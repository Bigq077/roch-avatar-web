<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Roch Avatar Chat Test</title>
  <style>
    body { font-family: Arial, sans-serif; max-width: 860px; margin: 40px auto; padding: 0 16px; }
    #chat { border: 1px solid #ddd; border-radius: 8px; padding: 12px; min-height: 220px; max-height: 360px; overflow:auto; }
    .msg { margin: 10px 0; }
    .me { font-weight: 700; }
    .ai { font-weight: 700; }
    textarea { width: 100%; height: 70px; padding: 10px; }
    button { padding: 10px 14px; cursor: pointer; }
    button[disabled] { opacity: 0.5; cursor: not-allowed; }
    .row { display: flex; gap: 10px; align-items: center; margin-top: 10px; flex-wrap: wrap; }
    input { padding: 8px; }
    small { color: #666; }
    .hint { margin-top: 8px; }
    .card { border:1px solid #eee; border-radius: 12px; padding:12px; }
    #avatarWrap { display:flex; gap:16px; flex-wrap: wrap; align-items:flex-start; }
    #avatarVideo {
      width: 320px;
      max-width: 100%;
      border-radius: 12px;
      background: #000;
    }
    #status { min-height: 18px; }
  </style>
</head>
<body>
  <h1>Roch Avatar Chat ‚Äî Interactive Avatar</h1>
  <p><small>Text + Voice ‚Üí AI brain ‚Üí HeyGen video (fallback: Deepgram TTS)</small></p>

  <div class="row">
    <label>Clinic ID:</label>
    <input id="clinicId" value="demo" />
    <label>Session ID:</label>
    <input id="sessionId" />
  </div>

  <div id="avatarWrap" class="row">
    <div class="card">
      <div style="display:flex; align-items:center; justify-content:space-between; gap:12px;">
        <strong>Avatar</strong>
        <label style="display:flex; align-items:center; gap:6px; font-size: 13px;">
          <input type="checkbox" id="muteToggle" checked />
          Muted (autoplay-friendly)
        </label>
      </div>
      <video id="avatarVideo" playsinline autoplay muted controls></video>
      <div style="margin-top:8px;">
        <small>
          Tip: after your first click/interaction, you can unmute and autoplay will keep working.
        </small>
      </div>
    </div>

    <div style="flex:1; min-width: 320px;">
      <div id="chat"></div>

      <div class="row">
        <textarea id="message" placeholder="Type a question (e.g. 'What are your opening hours?')"></textarea>
      </div>

      <div class="row">
        <button id="sendBtn">Send</button>
        <button id="recBtn">üéô Record</button>
        <button id="stopRecBtn" disabled>‚èπ Stop</button>
        <span id="status"></span>
      </div>

      <p class="hint">
        <small>
          Text ‚Üí <code>/avatar/video/start</code> + poll <code>/avatar/video/status</code><br/>
          Voice in ‚Üí <code>/avatar/voice-turn</code> (STT) ‚Üí then video start + poll<br/>
          Fallback voice out ‚Üí <code>/avatar/tts</code>
        </small>
      </p>
    </div>
  </div>

  <script>
    // ---------------------------
    // CONFIG
    // ---------------------------
    const BACKEND_BASE_URL = "https://rochsolutions-ai-receptionist.onrender.com";
    const POLL_INTERVAL_MS = 1500;
    const POLL_MAX_TRIES = 40; // ~60s

    // ---------------------------
    // SESSION
    // ---------------------------
    const sessionIdInput = document.getElementById("sessionId");
    const clinicIdInput = document.getElementById("clinicId");
    const existing = localStorage.getItem("roch_session_id");
    const newId = existing || (crypto.randomUUID ? crypto.randomUUID() : String(Date.now()));
    localStorage.setItem("roch_session_id", newId);
    sessionIdInput.value = newId;

    const chat = document.getElementById("chat");
    const statusEl = document.getElementById("status");

    const sendBtn = document.getElementById("sendBtn");
    const messageEl = document.getElementById("message");

    const recBtn = document.getElementById("recBtn");
    const stopRecBtn = document.getElementById("stopRecBtn");

    const videoEl = document.getElementById("avatarVideo");
    const muteToggle = document.getElementById("muteToggle");
    muteToggle.addEventListener("change", () => {
      videoEl.muted = muteToggle.checked;
    });

    function setStatus(text) {
      statusEl.textContent = text || "";
    }

    function setBusy(isBusy) {
      sendBtn.disabled = isBusy;
      recBtn.disabled = isBusy;
      // stopRecBtn stays controlled by recorder state
      messageEl.disabled = isBusy;
      clinicIdInput.disabled = isBusy;
      sessionIdInput.disabled = isBusy;
    }

    function addMsg(who, text) {
      const div = document.createElement("div");
      div.className = "msg";
      div.innerHTML = `<span class="${who === "You" ? "me" : "ai"}">${who}:</span> ${escapeHtml(text)}`;
      chat.appendChild(div);
      chat.scrollTop = chat.scrollHeight;
    }

    function escapeHtml(str) {
      return String(str).replace(/[&<>"']/g, m => ({
        "&":"&amp;","<":"&lt;",">":"&gt;",'"':"&quot;","'":"&#039;"
      }[m]));
    }

    function sleep(ms) {
      return new Promise(r => setTimeout(r, ms));
    }

    // ---------------------------
    // VIDEO AVATAR FLOW (HeyGen)
    // ---------------------------
    async function startVideoFromText(text) {
      const clinic_id = clinicIdInput.value.trim();
      const session_id = sessionIdInput.value.trim();

      const res = await fetch(`${BACKEND_BASE_URL}/avatar/video/start`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ clinic_id, session_id, text })
      });

      if (!res.ok) throw new Error(await res.text());
      return await res.json(); // { reply_text, video_id, session_id }
    }

    async function pollVideo(video_id) {
      for (let i = 0; i < POLL_MAX_TRIES; i++) {
        const res = await fetch(`${BACKEND_BASE_URL}/avatar/video/status?video_id=${encodeURIComponent(video_id)}`);
        if (!res.ok) throw new Error(await res.text());
        const data = await res.json(); // { status, video_url }

        if (data.status === "completed" && data.video_url) return data.video_url;
        if (data.status === "failed") return null;

        await sleep(POLL_INTERVAL_MS);
      }
      return null; // timeout
    }

    async function playVideo(url) {
      // Reset and play
      videoEl.pause();
      videoEl.currentTime = 0;
      videoEl.src = url;

      // Some browsers need play() to be triggered after a user gesture.
      // We already have a gesture (button click) for send/record.
      try {
        await videoEl.play();
      } catch (e) {
        // If autoplay fails due to policy, user can click play (controls enabled)
        console.warn("Video play blocked:", e);
      }
    }

    // ---------------------------
    // DEEPGRAM TTS (fallback)
    // ---------------------------
    async function speakViaBackend(text) {
      if (!text) return;
      try {
        const res = await fetch(`${BACKEND_BASE_URL}/avatar/tts`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text })
        });

        if (!res.ok) throw new Error(await res.text());
        const data = await res.json();

        const audio = new Audio(`data:${data.mime_type};base64,${data.audio_b64}`);
        await audio.play();
      } catch (err) {
        console.error("TTS error:", err);
      }
    }

    // ---------------------------
    // TEXT SEND
    // ---------------------------
    async function send() {
      const message = messageEl.value.trim();
      if (!message) return;

      addMsg("You", message);
      messageEl.value = "";

      setBusy(true);
      setStatus("Thinking‚Ä¶");

      try {
        // 1) Start generation (fast)
        const startData = await startVideoFromText(message);
        const replyText = startData.reply_text || "(no reply)";
        const videoId = startData.video_id;

        addMsg("AI", replyText);

        // 2) Poll
        setStatus("Generating video‚Ä¶");
        const videoUrl = await pollVideo(videoId);

        // 3) Play or fallback
        if (videoUrl) {
          setStatus("Playing‚Ä¶");
          await playVideo(videoUrl);
          setStatus("OK");
        } else {
          setStatus("Video failed ‚Äî playing audio fallback‚Ä¶");
          await speakViaBackend(replyText);
          setStatus("OK");
        }
      } catch (err) {
        console.error(err);
        setStatus("Error ‚Äî fallback to audio‚Ä¶");
        // As a fallback of fallback, we can at least TTS the typed message response by calling /avatar/chat,
        // but you asked to keep it simple. For now, just show error.
        setStatus("Error");
      } finally {
        setBusy(false);
      }
    }

    sendBtn.onclick = send;
    messageEl.onkeydown = e => {
      if (e.key === "Enter" && !e.shiftKey) {
        e.preventDefault();
        send();
      }
    };

    // Re-enable mic after video ends
    videoEl.addEventListener("ended", () => {
      setStatus("Your turn ‚Äî speak or type.");
    });

    // ---------------------------
    // VOICE INPUT (STT) -> VIDEO
    // ---------------------------
    let mediaRecorder, audioChunks = [], stream;

    recBtn.onclick = async () => {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch (e) {
        alert("Microphone permission denied.");
        return;
      }

      audioChunks = [];
      mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm;codecs=opus" });

      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);

      mediaRecorder.onstop = async () => {
        stream.getTracks().forEach(t => t.stop());
        const blob = new Blob(audioChunks, { type: "audio/webm" });
        await handleVoiceBlob(blob);
      };

      mediaRecorder.start();
      recBtn.disabled = true;
      stopRecBtn.disabled = false;
      setStatus("Recording‚Ä¶");
    };

    stopRecBtn.onclick = () => {
      mediaRecorder.stop();
      stopRecBtn.disabled = true;
      setStatus("Uploading‚Ä¶");
    };

    async function handleVoiceBlob(blob) {
      setBusy(true);

      try {
        // 1) Send to STT endpoint (returns transcript)
        const fd = new FormData();
        fd.append("clinic_id", clinicIdInput.value.trim());
        fd.append("session_id", sessionIdInput.value.trim());
        fd.append("audio", blob, "speech.webm");

        const sttRes = await fetch(`${BACKEND_BASE_URL}/avatar/voice-turn`, {
          method: "POST",
          body: fd
        });

        if (!sttRes.ok) throw new Error(await sttRes.text());
        const sttData = await sttRes.json();

        const transcript = (sttData.transcript || "").trim();
        if (!transcript) {
          setStatus("Could not transcribe ‚Äî try again.");
          return;
        }

        addMsg("You", transcript);

        // 2) Generate video from transcript (this calls brain once, in /video/start)
        setStatus("Thinking‚Ä¶");
        const startData = await startVideoFromText(transcript);
        const replyText = startData.reply_text || "(no reply)";
        const videoId = startData.video_id;

        addMsg("AI", replyText);

        // 3) Poll + Play
        setStatus("Generating video‚Ä¶");
        const videoUrl = await pollVideo(videoId);

        if (videoUrl) {
          setStatus("Playing‚Ä¶");
          await playVideo(videoUrl);
          setStatus("OK");
        } else {
          setStatus("Video failed ‚Äî playing audio fallback‚Ä¶");
          await speakViaBackend(replyText);
          setStatus("OK");
        }
      } catch (err) {
        console.error(err);
        setStatus("Error");
      } finally {
        setBusy(false);
        recBtn.disabled = false;
        stopRecBtn.disabled = true;
      }
    }
  </script>
</body>
</html>
